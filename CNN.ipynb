{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJbUA074rGbw",
    "outputId": "2e409e74-852d-413a-f85d-2147436579be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "Is using GPU? False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is using GPU?', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2E-wZ1d0rIEl"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dwXGoxZerIHr",
    "outputId": "74883cde-4fd7-4120-a54c-693bf5cbe5ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harassment_shv1.mp4_frame0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harassment_shv1.mp4_frame1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harassment_shv1.mp4_frame10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harassment_shv1.mp4_frame11.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harassment_shv1.mp4_frame12.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image  class\n",
       "0   harassment_shv1.mp4_frame0.jpg      1\n",
       "1   harassment_shv1.mp4_frame1.jpg      1\n",
       "2  harassment_shv1.mp4_frame10.jpg      1\n",
       "3  harassment_shv1.mp4_frame11.jpg      1\n",
       "4  harassment_shv1.mp4_frame12.jpg      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nD7oYva8rIKe",
    "outputId": "5134270b-37fd-424a-bab8-c87e51e45a98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 813/813 [00:16<00:00, 48.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(813, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = Image.open('train/' + train['image'][i]).resize((224, 224))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img / 255.0\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Z0yAyqFkrkW9"
   },
   "outputs": [],
   "source": [
    "y = train['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mm6kcUOb7ISS",
    "outputId": "b6f721c1-4990-46df-c772-effd6a328f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 224, 224, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 222, 222, 32)     1344      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 111, 111, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_5 (Separab  (None, 109, 109, 64)     4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 54, 54, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 54, 54, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 54, 54, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 52, 52, 128)      17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 26, 26, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_7 (Separab  (None, 24, 24, 256)      68096     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               9437440   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,952,770\n",
      "Trainable params: 9,951,810\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Input, Dense\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    def add_conv_block(model, num_filters):\n",
    "        \n",
    "        model = Conv2D(num_filters, 3, activation='relu', padding='same')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        model = SeparableConv2D(num_filters, 3, activation='relu', padding='valid')(model)\n",
    "        model = MaxPooling2D(pool_size=2)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    x = add_conv_block(inputs, 32)\n",
    "    x = add_conv_block(x, 64)\n",
    "    x = add_conv_block(x, 128)\n",
    "    x = add_conv_block(x, 256)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HvY1Ysy8MVc",
    "outputId": "32fed179-bfd3-4aab-bd34-a3029d6ba392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\copzt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 76s 11s/step - loss: 1.5446 - accuracy: 0.5015 - val_loss: 0.6929 - val_accuracy: 0.5399\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 76s 12s/step - loss: 0.7243 - accuracy: 0.5708 - val_loss: 0.6930 - val_accuracy: 0.5399\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 77s 12s/step - loss: 0.6522 - accuracy: 0.6185 - val_loss: 0.6929 - val_accuracy: 0.5399\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 76s 12s/step - loss: 0.6185 - accuracy: 0.6585 - val_loss: 0.6924 - val_accuracy: 0.5399\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 76s 12s/step - loss: 0.5459 - accuracy: 0.7015 - val_loss: 0.6920 - val_accuracy: 0.5399\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 74s 12s/step - loss: 0.5226 - accuracy: 0.7292 - val_loss: 0.6919 - val_accuracy: 0.5399\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 74s 12s/step - loss: 0.4413 - accuracy: 0.7723 - val_loss: 0.6917 - val_accuracy: 0.5399\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 75s 12s/step - loss: 0.3737 - accuracy: 0.8277 - val_loss: 0.6915 - val_accuracy: 0.5399\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 74s 12s/step - loss: 0.3325 - accuracy: 0.8523 - val_loss: 0.6915 - val_accuracy: 0.5399\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 75s 12s/step - loss: 0.2848 - accuracy: 0.8708 - val_loss: 0.6915 - val_accuracy: 0.5399\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Set up a checkpoint to save the best model weights\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OZa1zAvdCyav",
    "outputId": "3c75c97f-bcee-45b2-a6d2-d0e3ebd7194b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harassment/harassment_shv4.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harassment/harassment_shv8.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harassment/harassment_shv14.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harassment/harassment_shv18.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non_harassment/non4.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        video_name\n",
       "0   harassment/harassment_shv4.mp4\n",
       "1   harassment/harassment_shv8.mp4\n",
       "2  harassment/harassment_shv14.mp4\n",
       "3  harassment/harassment_shv18.mp4\n",
       "4          non_harassment/non4.mp4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test list\n",
    "f = open(\"test.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating the dataframe\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:-1]\n",
    "test_videos = test['video_name']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9kgOFb-ZCzcY"
   },
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('Data/train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01CDU1rw88vz",
    "outputId": "250d6f61-6184-4fb4-c673-01d4db4bf2b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "import os\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# removing all files from the temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_videos.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = test_videos[i]\n",
    "    videoPath = os.path.join('Data', videoFile)\n",
    "    cap = cv2.VideoCapture(videoPath)  # capturing the video from the given path\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        # Skip iteration if video capture fails\n",
    "        continue\n",
    "    \n",
    "    frameRate = cap.get(5)  # frame rate\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        frameId = cap.get(1)  # current frame number\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frameId % 3 == 0:\n",
    "            # storing the frames of this particular video in temp folder\n",
    "            filename = os.path.join('temp', f'_frame{count}.jpg')\n",
    "            cv2.imwrite(filename, frame)\n",
    "            count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"temp/*.jpg\")\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        # Skip iteration if no valid images found\n",
    "        continue\n",
    "    \n",
    "    prediction_images = []\n",
    "    for img_path in images:\n",
    "        img = image.load_img(img_path, target_size=(224, 224, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    \n",
    "    # predicting tags for each array\n",
    "    prediction = model.predict_on_batch(prediction_images)\n",
    "    \n",
    "    # converting features to one-dimensional array\n",
    "    prediction_labels = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(1 if np.sum(prediction_labels) >= 5 else 0)\n",
    "    \n",
    "    # appending the actual tag of the video\n",
    "    if videoFile.split('/')[1].split('_')[0] == 'harassment':\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2x5tr0GmCpCM",
    "outputId": "71707981-7928-45b8-ea96-9863d16cdefa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6gG_t9KvUiiB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(actual)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Harassment _Final_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
