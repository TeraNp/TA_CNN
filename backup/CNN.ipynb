{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJbUA074rGbw",
    "outputId": "2e409e74-852d-413a-f85d-2147436579be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "WARNING:tensorflow:From C:\\Users\\myasy\\AppData\\Local\\Temp\\ipykernel_7908\\1596216831.py:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is using GPU? False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is using GPU?', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2E-wZ1d0rIEl"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dwXGoxZerIHr",
    "outputId": "74883cde-4fd7-4120-a54c-693bf5cbe5ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harassment_shv1.mp4_frame0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harassment_shv1.mp4_frame1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harassment_shv1.mp4_frame10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harassment_shv1.mp4_frame11.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harassment_shv1.mp4_frame12.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image  class\n",
       "0   harassment_shv1.mp4_frame0.jpg      1\n",
       "1   harassment_shv1.mp4_frame1.jpg      1\n",
       "2  harassment_shv1.mp4_frame10.jpg      1\n",
       "3  harassment_shv1.mp4_frame11.jpg      1\n",
       "4  harassment_shv1.mp4_frame12.jpg      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nD7oYva8rIKe",
    "outputId": "5134270b-37fd-424a-bab8-c87e51e45a98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:22<00:00, 34.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(757, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = Image.open('train/' + train['image'][i]).resize((224, 224))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img / 255.0\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Z0yAyqFkrkW9"
   },
   "outputs": [],
   "source": [
    "y = train['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=80, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    353\n",
       "1    214\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mm6kcUOb7ISS",
    "outputId": "b6f721c1-4990-46df-c772-effd6a328f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 222, 222, 32)     1344      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 111, 111, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 109, 109, 64)     4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 54, 54, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 54, 54, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54, 54, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 52, 52, 128)      17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 26, 26, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 24, 24, 256)      68096     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               9437440   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,952,770\n",
      "Trainable params: 9,951,810\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Input, Dense\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    def add_conv_block(model, num_filters):\n",
    "        \n",
    "        model = Conv2D(num_filters, 3, activation='relu', padding='same')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        model = SeparableConv2D(num_filters, 3, activation='relu', padding='valid')(model)\n",
    "        model = MaxPooling2D(pool_size=2)(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    x = add_conv_block(inputs, 32)\n",
    "    x = add_conv_block(x, 64)\n",
    "    x = add_conv_block(x, 128)\n",
    "    x = add_conv_block(x, 256)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HvY1Ysy8MVc",
    "outputId": "32fed179-bfd3-4aab-bd34-a3029d6ba392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 384s 77s/step - loss: 1.1093 - accuracy: 0.5421 - val_loss: 0.6916 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 408s 81s/step - loss: 0.7287 - accuracy: 0.5868 - val_loss: 0.6923 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 407s 81s/step - loss: 0.6484 - accuracy: 0.6281 - val_loss: 0.6911 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 387s 77s/step - loss: 0.6303 - accuracy: 0.6529 - val_loss: 0.6897 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 398s 80s/step - loss: 0.5899 - accuracy: 0.6711 - val_loss: 0.6890 - val_accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 393s 78s/step - loss: 0.5530 - accuracy: 0.7058 - val_loss: 0.6891 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 401s 80s/step - loss: 0.4875 - accuracy: 0.7587 - val_loss: 0.6887 - val_accuracy: 0.6250\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 400s 80s/step - loss: 0.4024 - accuracy: 0.8099 - val_loss: 0.6872 - val_accuracy: 0.6250\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 419s 83s/step - loss: 0.3246 - accuracy: 0.8678 - val_loss: 0.6858 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 415s 81s/step - loss: 0.2488 - accuracy: 0.9107 - val_loss: 0.6825 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Set up a checkpoint to save the best model weights\n",
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OZa1zAvdCyav",
    "outputId": "3c75c97f-bcee-45b2-a6d2-d0e3ebd7194b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test list\n",
    "f = open(\"test.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating the dataframe\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:-1]\n",
    "test_videos = test['video_name']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9kgOFb-ZCzcY"
   },
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('Data/train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     harassment/harassment_shv4.mp4\n",
       "1     harassment/harassment_shv8.mp4\n",
       "2    harassment/harassment_shv14.mp4\n",
       "3    harassment/harassment_shv18.mp4\n",
       "4            non_harassment/non4.mp4\n",
       "5            non_harassment/non8.mp4\n",
       "6           non_harassment/non14.mp4\n",
       "7           non_harassment/non18.mp4\n",
       "8                                   \n",
       "Name: video_name, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01CDU1rw88vz",
    "outputId": "250d6f61-6184-4fb4-c673-01d4db4bf2b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:02<00:17,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:05<00:20,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:09<00:21,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:14<00:19,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:21<00:20,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:40<00:29,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:59<00:25, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [01:25<00:17, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:26<00:00,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "import os\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# removing all files from the temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "count = 0\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_videos.shape[0])):\n",
    "    \n",
    "    videoFile = test_videos[i]\n",
    "    videoPath = os.path.join('Data', videoFile)\n",
    "    cap = cv2.VideoCapture(videoPath)  # capturing the video from the given path\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"halo\")\n",
    "        # Skip iteration if video capture fails\n",
    "        continue\n",
    "    \n",
    "    frameRate = cap.get(5)  # frame rate\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        frameId = cap.get(1)  # current frame number\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frameId % 3 == 0:\n",
    "            # storing the frames of this particular video in temp folder\n",
    "            filename = os.path.join('temp', f'_frame{count}.jpg')\n",
    "            cv2.imwrite(filename, frame)\n",
    "            count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"temp/*.jpg\")\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        # Skip iteration if no valid images found\n",
    "        continue\n",
    "    \n",
    "    prediction_images = []\n",
    "    for img_path in images:\n",
    "        img = image.load_img(img_path, target_size=(224, 224, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    \n",
    "    # predicting tags for each array\n",
    "    prediction = model.predict_on_batch(prediction_images)\n",
    "    \n",
    "    # converting features to one-dimensional array\n",
    "    prediction_labels = np.argmax(prediction, axis=1)\n",
    "    print(prediction_labels)\n",
    "    \n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(1 if np.sum(prediction_labels) >= 5 else 0)\n",
    "    \n",
    "    # appending the actual tag of the video\n",
    "    if videoFile.split('/')[1].split('_')[0] == 'harassment':\n",
    "        actual.append(1)\n",
    "    else:\n",
    "        actual.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_testing\\\\_frame0.jpg', 'frame_testing\\\\_frame1.jpg', 'frame_testing\\\\_frame2.jpg', 'frame_testing\\\\_frame3.jpg', 'frame_testing\\\\_frame4.jpg', 'frame_testing\\\\_frame5.jpg', 'frame_testing\\\\_frame6.jpg', 'frame_testing\\\\_frame7.jpg', 'frame_testing\\\\_frame8.jpg', 'frame_testing\\\\_frame9.jpg']\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "[0]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "[0]\n",
      "[array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "images_test = glob(\"frame_testing/*.jpg\")\n",
    "print(images_test)\n",
    "testing_predict = []\n",
    "for img_path in images_test:\n",
    "        img = image.load_img(img_path, target_size=(224, 224, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        # predicting tags for each array\n",
    "        testing_prediction = model.predict(img)\n",
    "\n",
    "        # converting features to one-dimensional array\n",
    "        pred = np.argmax(testing_prediction, axis=1)\n",
    "        print(pred)\n",
    "        testing_predict.append(pred)\n",
    "print(testing_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2x5tr0GmCpCM",
    "outputId": "71707981-7928-45b8-ea96-9863d16cdefa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6gG_t9KvUiiB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(actual)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Harassment _Final_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
